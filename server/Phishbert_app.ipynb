{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1673a304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\program_files\\python311\\lib\\site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in d:\\program_files\\python311\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\program_files\\python311\\lib\\site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\program_files\\python311\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\program_files\\python311\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\program_files\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\program_files\\python311\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in d:\\program_files\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\program_files\\python311\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\program_files\\python311\\lib\\site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\program_files\\python311\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in d:\\program_files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\program_files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in d:\\program_files\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program_files\\python311\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program_files\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\program_files\\python311\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program_files\\python311\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydantic 2.3.0 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.6.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\program_files\\python311\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.2)\n",
      "Requirement already satisfied: setuptools in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\program_files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\program_files\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\program_files\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in d:\\program_files\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\program_files\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\program_files\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\program_files\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\program_files\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\program_files\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\program_files\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in d:\\program_files\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\program_files\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program_files\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program_files\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program_files\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\program_files\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\program_files\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\program_files\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "Successfully installed typing-extensions-4.5.0\n",
      "Collecting tldextract\n",
      "  Downloading tldextract-3.6.0-py3-none-any.whl (97 kB)\n",
      "                                              0.0/97.4 kB ? eta -:--:--\n",
      "     ------------                             30.7/97.4 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------    92.2/97.4 kB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 97.4/97.4 kB 926.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: idna in d:\\program_files\\python311\\lib\\site-packages (from tldextract) (3.4)\n",
      "Requirement already satisfied: requests>=2.1.0 in d:\\program_files\\python311\\lib\\site-packages (from tldextract) (2.31.0)\n",
      "Collecting requests-file>=1.4 (from tldextract)\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in d:\\program_files\\python311\\lib\\site-packages (from tldextract) (3.12.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program_files\\python311\\lib\\site-packages (from requests>=2.1.0->tldextract) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\program_files\\python311\\lib\\site-packages (from requests>=2.1.0->tldextract) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program_files\\python311\\lib\\site-packages (from requests>=2.1.0->tldextract) (2023.7.22)\n",
      "Requirement already satisfied: six in d:\\program_files\\python311\\lib\\site-packages (from requests-file>=1.4->tldextract) (1.16.0)\n",
      "Installing collected packages: requests-file, tldextract\n",
      "Successfully installed requests-file-1.5.1 tldextract-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install tensorflow\n",
    "!pip install tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848103b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Final_phishhalt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Final_phishhalt\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "max_length=272\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "# Define the model architecture\n",
    "input_layer = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name=\"input_ids\")\n",
    "bert_output = bert_model(input_layer)\n",
    "output = tf.keras.layers.Dense(32, activation=\"relu\")(bert_output[0])\n",
    "output = tf.keras.layers.Dense(2, activation=\"softmax\")(output)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)  # Adjust learning rate as needed\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "model.load_weights(r\"C:\\Users\\venka\\OneDrive\\Desktop\\UI\\server\\phishbert_checkpoint_ mix_new_data_200.h5\")\n",
    "model.save(\"Final_phishhalt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2c653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tldextract\n",
      "  Downloading tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\venka\\.conda\\envs\\py310\\lib\\site-packages (from tldextract) (2.10)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\venka\\.conda\\envs\\py310\\lib\\site-packages (from tldextract) (2.31.0)\n",
      "Collecting requests-file>=1.4 (from tldextract)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\venka\\.conda\\envs\\py310\\lib\\site-packages (from tldextract) (3.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\venka\\.conda\\envs\\py310\\lib\\site-packages (from requests>=2.1.0->tldextract) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\venka\\.conda\\envs\\py310\\lib\\site-packages (from requests>=2.1.0->tldextract) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\venka\\.conda\\envs\\py310\\lib\\site-packages (from requests>=2.1.0->tldextract) (2023.7.22)\n",
      "Downloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/97.6 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/97.6 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 30.7/97.6 kB 325.1 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 41.0/97.6 kB 326.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 97.6/97.6 kB 619.3 kB/s eta 0:00:00\n",
      "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Installing collected packages: requests-file, tldextract\n",
      "Successfully installed requests-file-2.1.0 tldextract-5.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b22f47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "from urllib.parse import *\n",
    "import tldextract\n",
    "import re\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "phishhalt=tf.saved_model.load(\"Final_phishhalt\")\n",
    "\n",
    "def validate(url):\n",
    "    d=[]\n",
    "\n",
    "    def doml(s):\n",
    "        e = tldextract.extract(s)\n",
    "        return len(e.domain)\n",
    "\n",
    "    def pathl(s):\n",
    "        parsed_url = urlparse(s)\n",
    "        path_component = parsed_url.path\n",
    "        return len(path_component)\n",
    "\n",
    "    def spec(s):\n",
    "        special = re.findall(r'[^a-zA-Z0-9]',s)\n",
    "        return len(special)\n",
    "\n",
    "    def ippres(s):\n",
    "        parsed_url = urlparse(url)\n",
    "        hostname = parsed_url.hostname\n",
    "\n",
    "        if hostname:\n",
    "            # Regular expression to match an IPv4 address\n",
    "            ip_regex = r\"\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b\"\n",
    "\n",
    "            # Check if the hostname contains an IP address\n",
    "            if re.search(ip_regex, hostname):\n",
    "                return 1\n",
    "        return 0\n",
    "    def embed1(url):\n",
    "        return tokenizer.encode_plus(url, add_special_tokens=True, max_length=128, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    d.append(len(url))\n",
    "    d.append(doml(url))\n",
    "    d.append(url.count('.'))\n",
    "    d.append(pathl(url))\n",
    "    d.append(url.count('?'))\n",
    "    d.append(spec(url))\n",
    "    d.append(ippres(url))\n",
    "    d.append(url.count('//'))\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    res=embed1(url)\n",
    "    inp=res[\"input_ids\"]\n",
    "    mask=res[\"attention_mask\"]\n",
    "    feature=torch.tensor(d)\n",
    "    input_feature=torch.cat((inp[0],feature),dim=0)\n",
    "    e = torch.ones(len(d)).int()\n",
    "    input_mask= torch.cat((mask[0], e),dim=0)\n",
    "    input_val=tf.convert_to_tensor(torch.cat((input_feature,input_mask),dim=0))\n",
    "    x=tf.convert_to_tensor([input_val])\n",
    "    y=phishhalt(x)\n",
    "    print(f\"Phishing possibility {int(y[0][1]*100)}%\")\n",
    "    return int(y[0][1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "199bfb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phishing possibility 98%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\"http://www.hdfc-jao-kokobank.com/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
